'''
An instance of Predictive Service can be created using create()
'''
from logging import getLogger as _getLogger
import time as _time
from re import compile as _compile
from uuid import uuid4 as _random_uuid
import os as _os
import datetime as _datetime

from boto import connect_s3 as _connect_s3
from boto.ec2.elb import connect_to_region as _lb_connection
from boto.exception import S3ResponseError as _S3ResponseError

from graphlab.connect.aws._ec2 import get_credentials as _get_credentials
import graphlab as _gl
import graphlab.connect as _mt
from requests import ConnectionError as _ConnectionError

# since _predictive_service_environment imports these, need to have them defined first
from _predictive_service import _MAX_CREATE_TIMEOUT_SECS
from _predictive_service._policy import EpsilonGreedyPolicy, ProbabilityPolicy

# constants
_CORS_ORIGIN_SECTION_NAME_ = 'CORS Origin'
_CACHE_STATE_SECTION_NAME_ = 'Global Cache State'

from _predictive_service._system_config import SystemConfig as _SystemConfig
from _predictive_service._predictive_service_environment import \
    Ec2PredictiveServiceEnvironment as _Ec2PredictiveServiceEnvironment, \
    predictive_service_environment_factory as _predictive_service_environment_factory, \
    PredictiveServiceEnvironment as _PredictiveServiceEnvironment

from graphlab.util import file_util as _file_util

from _predictive_service._predictive_service_environment import PORT_DEFAULT_NUM as _PORT_DEFAULT_NUM
from _predictive_service._predictive_service import NODE_LAUNCH_LIMIT as _NODE_LAUNCH_LIMIT
from _predictive_service._predictive_service import PredictiveService as _PredictiveService
from  _predictive_service import PREDICTIVE_SERVICE_SCHEMA_VERSION

_logger = _getLogger(__name__)
_name_checker = _compile('^[a-zA-Z-]+$')

def create(name, ec2_config, state_path, num_hosts = 1, description = None,
           api_key = None, admin_key = None, ssl_credentials = None, cors_origin = '',
           port = _PORT_DEFAULT_NUM):
    '''
    Launch a Predictive Services cluster. This cluster can currently be launched
    on EC2 by specifying an EC2 environment.

    Parameters
    ----------
    name : str
        The name of the Predictive Service that will be launched.

        This string can only contain: a-z, A-Z and hyphens.

    ec2_config : :class:`~graphlab.deploy.Ec2Config`
        Must be an EC2 Configuration object used for starting up EC2 host(s).
        This configuration should contain the instance type, region, aws
        credientials, and other information used to launch EC2 host(s).

    state_path :  str
        S3 path used to manage state for the Predictive Service. This path can
        also be used to create the Predictive Service object on another
        computer.

    num_hosts : int, optional
        The number of EC2 host(s) to use for this Predictive Service. The default
        number of EC2 host(s) is 1.

    description : str, optional
        Description of this Predictive Service.

    api_key : str, optional
        An API key that client must included with requests. If an api_key is
        not specified, one will be auto generated. The API Key can be retrieved
        from the return PredictiveService object.

    admin_key : str, optional
        An API key used for control operations (i.e. anything other than client
        requests). If an admin_key is not specified, one will be auto generated.
        The API Key can be retrieved from the return PredictiveService object.


    ssl_credentials : tuple of len three, with types: str, str, bool.
        The first string is the path to the private key file. The second string
        is the path to public key certificate. The third denotes whether the
        certificates are self signed (and any client should not verify the
        certificate).

        These files must be in the precise format AWS expects. Such a private
        key and a self-signed certificate can be generated using openssl with
        following commands:

        >>> openssl genrsa 1024 > privatekey.pem
        >>> openssl req -new -key privatekey.pem -out csr.pem
        >>> openssl x509 -req -days 365 -in csr.pem -signkey privatekey.pem -out server.crt

        If a tuple is not given, requests will be served over HTTP rather than
        HTTPS (i.e.  encryption will not be used).

    cors_origin : str, optional
        The string value to use as HTTP header Access-Control-Allow-Origin,
        in order to support Cross-Origin Resource Sharing as described in
        https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS.
        The default value is ''. If '' (empty String) is specified, CORS
        support will be disabled. If the string value is '*', CORS support
        will be enabled for all URIs. If the string value is
        'https://dato.com', CORS support will be enabled for
        'https://dato.com' only.

    port : int, optional
        The port the server listens to . The default port is 9005.
        Please do not specify 9006 or 19006. These are reserved for cache.

    Returns
    -------
    out : :py:class:`~graphlab.deploy.PredictiveService`
        A Predictive Service object which can be used to manage the deployment.

    See Also
    --------
    graphlab.deploy.predictive_service.load, graphlab.deploy.PredictiveService

    Examples
    --------
    Let us start out by creating a single node Predictive Serivce on EC2.

    .. sourcecode:: python

        # create an Ec2Config for Predictive Service, with region, instance_type,
        # and aws credientials.
        ec2 = graphlab.deploy.Ec2Config(aws_access_key_id = 'ACCESS_KEY_ID',
                                        aws_secret_access_key = 'SECRET')

        # create a Predictive Service using a name, ec2 config, and
        # a directory to store the Predictive Service metadata and logs
        ps = graphlab.deploy.predictive_service.create('name',
                                                       ec2,
                                                       's3://mybucket/pred_services/name')

        # get status of this Predictive Service
        ps.get_status()

    Now, lets create a multi-node Predictive Service by specifying the number
    of nodes needed in the EC2 environment variable

    .. sourcecode:: python

        # create an Ec2Config for Predictive Service, with region, instance_type,
        # and aws credientials.
        ec2 = graphlab.deploy.Ec2Config(aws_access_key_id = 'ACCESS_KEY_ID',
                                        aws_secret_access_key = 'SECRET')

        # create the Predictive Service with 3 nodes
        ps = graphlab.deploy.predictive_service.create('name_cluster',
                                               ec2_cluster,
                                               's3://mybucket/pred_services/name_cluster',
                                               num_hosts = 3)

        # get status of this Predictive Service
        ps.get_status()

        # shut down this Predictive Service
        ps.terminate_service()

    '''
    if num_hosts > _NODE_LAUNCH_LIMIT:
        raise ValueError("You cannot launch more than %d nodes at one time. " \
                         "If this limit is problematic, please contact " \
                         "support@dato.com" % _NODE_LAUNCH_LIMIT)

    # Validate inputs for current session
    if _gl.deploy._default_session.exists(name, _PredictiveService._typename):
        # found another predictive service or predictive service endpoint with the same name
        raise ValueError("Validation Error: Predictive Service already exists with the name '%s', please rename or delete the existing Predictive Service." % name)

    # Validate Ec2 Config
    if not isinstance(ec2_config, _gl.deploy.Ec2Config):
        raise TypeError('Unsupported type given for ec2_config parameter. Must be an Ec2Config object.')

    # Save AWS config
    if(hasattr(ec2_config, 'aws_access_key_id') and hasattr(ec2_config, 'aws_secret_access_key')):
        aws_access_key = ec2_config.aws_access_key_id
        aws_secret_key = ec2_config.aws_secret_access_key
    else:
        try:
            aws_access_key, aws_secret_key = _get_credentials()
        except:
            raise IOError('No AWS credentials set. Credentials must either be set in the ' \
                              'ec2_config parameter or set globally using ' \
                              'graphlab.aws.set_credentials(...).')
    aws_credentials = {
        'aws_access_key_id': aws_access_key,
        'aws_secret_access_key': aws_secret_key
        }

    # Warn if specified bucket is in different region than specified in env.
    s3_bucket_name, _ = _file_util.parse_s3_path(state_path)

    __default_config_path = _os.path.join(_os.path.expanduser("~"), ".graphlab", "config")
    try:
        _file_util.upload_to_s3(__default_config_path, state_path + "/license",
                                aws_credentials = aws_credentials, silent = True)
        region = _file_util.get_s3_bucket_region(s3_bucket_name, aws_credentials)
    except _S3ResponseError as e:
        _logger.error("Unable to connect to state_path's bucket; check your AWS credentials")
        raise

    if region != ec2_config.region:
        _logger.warn("The bucket in your state path is in a different region " \
                     "(%s) than the one specified in your environment (%s). " \
                     "AWS data transfer rates apply. Additionally, upload and " \
                     "download speeds may be slower than expected. If this is " \
                     "not what you intended, abort this operation or " \
                     "terminate the service upon its completion, then be sure " \
                     "that your environment and S3 bucket are in the same " \
                     "region before relaunching." % (region, ec2_config.region))

    # Validate 'name' value
    if not _name_checker.match(name):
        raise ValueError('Predictive Service Name can only contain: a-z, A-Z and hyphens.')
    if len(name) > 32:
        raise ValueError("Predictive Service name can not be longer than 32 characters.")

    conn = _lb_connection(ec2_config.region, **aws_credentials)
    for lb in conn.get_all_load_balancers():
        if lb.name == name:
            raise IOError('There is already a load balancer with that name. Load balancer names' \
                              ' must be unique in their region. Please choose a different name.')

    tracker = _mt._get_metric_tracker()
    tracker.track('deploy.predictive_service.create', value=1,
            properties={'num_hosts':num_hosts, 'instance_type':ec2_config.instance_type})

    _logger.info("Launching Predictive Service with %d hosts, as specified by num_hosts parameter"
                 % (num_hosts))

    # Set defaults values, if needed
    if not api_key:
        api_key = str(_random_uuid())
    if not admin_key:
        admin_key = str(_random_uuid())

    result = None
    env = None
    try:
        starttime = _datetime.datetime.now()
        _logger.info("Launching Predictive Service, with name: %s" % name)

        _logger.info("[Step 0/5]: Initializing S3 locations.")
        # Create the predictive service object. It writes init state to S3.
        result = _PredictiveService(name, state_path, description, api_key, admin_key,
                                    aws_credentials, cors_origin = cors_origin, port = port)

        # Launch the environment.
        env = _Ec2PredictiveServiceEnvironment.launch(name, ec2_config, state_path, num_hosts, admin_key,
                                                      ssl_credentials, aws_credentials, started=starttime,
                                                      port = port)

        # Attach the launched environment and write all service state to S3.
        result._environment = env
        result._save_state()

        _logger.info("[Step 4/5]: Waiting for Load Balancer to put all instances into service.")
        while ((_datetime.datetime.now() - starttime).total_seconds() < _MAX_CREATE_TIMEOUT_SECS):
            # query status, verify all InService
            nodes = env.get_status(_show_errors = False)
            statuses = []
            for node in nodes:
                statuses.append(node['state'] == 'InService')
            if all(statuses):
                _logger.info("Cluster is fully operational, [%d/%d] instances currently in service." %
                        (statuses.count(True), len(statuses)))
                break
            else:
                _logger.info("Cluster not fully operational yet, [%d/%d] instances currently in service." %
                        (statuses.count(True), len(statuses)))
                _time.sleep(15)
        else:
            _logger.error("Instances failed to be ready within 10 minutes. Tearing down.")
            raise RuntimeError("Cluster configuration not successful in time, timing out.")

        _logger.info("[Step 5/5]: Finalizing Configuration.")

        result.cache_enable(None, True)

        _gl.deploy._default_session.register(result)
        result.save()

        return result
    except Exception as e:
        # any exceptions we should gracefully terminate / tear down what we've created
        _logger.warning("Tearing down Predictive Service due to error launching")

        # default behavior deletes the log files in tear down.
        # To preserve the logs set GRAPHLAB_DEBUG in environment, and the logs will be preserved
        delete_logs = True
        if 'GRAPHLAB_DEBUG' in _os.environ:
            _logger.info("Preserving Log Files for debugging purposes")
            delete_logs = False

        if env:
            env.terminate(delete_logs)

        if result and delete_logs:
            _logger.info('Deleting model data.')
            try:
                _file_util.s3_recursive_delete(state_path, aws_credentials)
            except:
                _logger.error("Could not delete model data. Please manually delete data under: %s" %
                              state_path)

        raise

def load(state_path, aws_access_key_id=None, aws_secret_access_key=None):
    '''
    Loads a Predictive Service object from the state_path.

    This will have the effect of instantiating an object locally, which contains
    all the relevant metadata associated with a Predictive Service. This is
    useful for getting a handle on a Predictive Service created from another
    machine, allowing you to query it and report its status, for example.

    Parameters
    -----------
    state_path : str
        State path used to manage state for the Predictive Service. This corresponds
        to the state path specified when the Predictive Service was initially
        created.

    aws_access_key_id : str
        The AWS Access Key to use to load the Predictive Service that was deployed
        to AWS. If this is not specified, your system environment variables will be
        used. You may also use :py:func:`~graphlab.aws.set_credentials` to set
        the credentials.

    aws_secret_access_key : str
        The AWS Access Key to use to load the Predictive Service that was deployed
        to AWS. If this is not specified, your system environment variables will be
        used. You may also use :py:func:`~graphlab.aws.set_credentials` to set
        the credentials.

    Returns
    -------
    out : :py:class:`~graphlab.deploy.PredictiveService`
        The Predictive Service handle that can be used to access and manage the
        deployed Predictive Service

    See Also
    --------
    graphlab.deploy.predictive_service.create, graphlab.deploy.PredictiveService

    Examples
    --------

    .. sourcecode:: python

        # load a Predictive Service from the state path that was used to create
        # the Predictive Service
        ps = graphlab.deploy.predictive_service.load('s3://mybucket/pred_services/name')

        # get status of this Predictive Service
        ps.get_status()

    '''
    result = _load_imp(state_path, aws_access_key_id, aws_secret_access_key)

    _mt._get_metric_tracker().track('deploy.predictive_service.load', value = 1, properties={'path': state_path})

    # register and save to session, if already exist, delete first
    if _gl.deploy._default_session.exists(result.name, _PredictiveService._typename):
        _logger.warning('Overwritting existing Predictive Service "%s" in local session.' % result.name)
        _gl.deploy.predictive_services.delete(result.name, silent=True)
    _gl.deploy._default_session.register(result)
    result.save()

    return result

def _load_imp(state_path, aws_access_key_id, aws_secret_access_key):
    '''
    Internal implmentation of the load, used by both external facing load and by
    internal facing load (gl.deploy.predictive_services[name])
    '''
    aws_credentials = None
    if _file_util.is_s3_path(state_path):
        # Save the credentials.
        if bool(aws_access_key_id) != bool(aws_secret_access_key):
            raise IOError('Either both aws_access_key_id and aws_secret_access_key ' \
                          'should be specified or neither should be specified.')
        if not aws_access_key_id and not aws_secret_access_key:
            try:
                aws_access_key_id, aws_secret_access_key = _get_credentials()
            except:
                raise IOError('No AWS credentials set. Credentials must either be ' \
                              'passed in, or set globally using ' \
                              'graphlab.aws.set_credentials(...).')
        aws_credentials = {
            'aws_access_key_id': aws_access_key_id,
            'aws_secret_access_key': aws_secret_access_key
        }

    elif (not _file_util.is_hdfs_path(state_path)) and (not _file_util.is_local_path(state_path)):
        raise ValueError("Invalid state path. Predictive Service only supports loading \
                        state path from S3, HDFS or Local file path.")

    config = _PredictiveServiceEnvironment._get_state_from_file(state_path, aws_credentials)
    name = config.get(_PredictiveService._SERVICE_INFO_SECTION_NAME, 'Name')
    description = config.get(_PredictiveService._SERVICE_INFO_SECTION_NAME, 'Description')
    api_key = config.get(_PredictiveService._SERVICE_INFO_SECTION_NAME, 'API Key')
    admin_key = config.get(_PredictiveService._ENVIRONMENT_SECTION_NAME, 'admin_key')
    # For backwards compatibility. Port used to be hard-coded as 9005 and does not
    # exist in the config.
    if (config.has_option(_PredictiveService._ENVIRONMENT_SECTION_NAME, 'port')):
        port = int(config.get(_PredictiveService._ENVIRONMENT_SECTION_NAME, 'port'))
    else:
        port = _PORT_DEFAULT_NUM

    global_cache_state = 'enabled'
    if _CACHE_STATE_SECTION_NAME_ in config.options(_PredictiveService._SERVICE_INFO_SECTION_NAME):
        global_cache_state = config.get(_PredictiveService._SERVICE_INFO_SECTION_NAME, _CACHE_STATE_SECTION_NAME_)

    cors_origin = ''
    if _CORS_ORIGIN_SECTION_NAME_ in config.options(_PredictiveService._SERVICE_INFO_SECTION_NAME):
        cors_origin = config.get(_PredictiveService._SERVICE_INFO_SECTION_NAME, _CORS_ORIGIN_SECTION_NAME_)

    system_config = _SystemConfig.from_config_parser(
        config, _PredictiveService._SYSTEM_SECTION_NAME)

    result = _PredictiveService(name, state_path, description, api_key, admin_key,
                                aws_credentials,
                                _new_service=False, cors_origin=cors_origin,
                                global_cache_state=global_cache_state,
                                system_config=system_config,
                                port = port)

    # create environment
    environment_info = dict(config.items(_PredictiveService._ENVIRONMENT_SECTION_NAME))
    if aws_credentials:
        environment_info['aws_credentials'] = aws_credentials
    result._environment = _predictive_service_environment_factory(environment_info)

    # get latest state
    result._get_latest_state()

    return result

def copy_ec2_predictive_object(source_ps, target_ps, source_po_name, target_po_name=None, update=False):
    '''
    Copy a predictive object from a source Predictive Service to a target
    Predictive Service.

    Parameters
    ----------
    source_ps : Predictive Service object
        The source Predictive Service that holds the predictive object specified
        in source_po_name.

    target_ps : Predictive Service object
        The target Predictive Service that will accept the predictive object
        copied from the source Predictive Service.

    source_po_name : str
        The name of the predictive object to be copied. Must exist on the
        source Predictive Service.

    target_po_name : str, optional
        The name of the predictive object to be stored to the target Predictive
        Service. If target_po_name is None, the target Predictive Service would use
        source_po_name as the predictive object name. Default value is None.

    update : boolean, optional
        If a predictive object already exists on the target Predictive Service
        with the name specified by target_po_name, set this to True if you want to
        update the existing predictive object on the target Predictive Service
        with the predictive object from the source Predictive Service. Otherwise,
        leave this to the default value False to prevent update.

    Notes
    -----
    This operation will by-pass `apply_changes` operation on the target Predictive
    Service to add/update the predictive object.

    Examples
    --------
    To copy a predictive object named 'recommender' from a source Predictive
    Service to a target Predictive Service:

        >>> gl.deploy.predictive_service.copy_predictive_object(source_ps, target_ps, 'recommender')

    To update the 'recommender' predictive object on the target Predictive Service
    with the 'recommender' predictive object from the source Predictive Service:

        >>> gl.deploy.predictive_service.copy_predictive_object(source_ps, target_ps, 'recommender', update=True)

    To copy the 'recommender' predictive object from the source Predictive Service
    to the target Predictive Service and rename it 'rec':

        >>> gl.deploy.predictive_service.copy_predictive_object(source_ps, target_ps, 'recommender', 'rec')

    '''
    if not source_ps or type(source_ps) is not _PredictiveService:
        raise ValueError("Invalid source Predictive Service.")
    source_ps._ensure_not_terminated()

    if not target_ps or type(target_ps) is not _PredictiveService:
        raise ValueError("Invalid target Predictive Service.")

    target_ps._ensure_not_terminated()

    # make sure both predictive services are deployed on AWS
    if not _file_util.is_s3_path(source_ps._state_path) or not _file_util.is_s3_path(target_ps._state_path):
        raise ValueError("Both source and target Predictive Services must be deployed on EC2")

    # if source is version 1, fail
    if source_ps._schema_version == 1:
        raise ValueError("The Predictive Service that you are trying to " \
                         "load is running version 1, which is no " \
                         "longer supported. Please re-create your " \
                         "Predictive Service using your current version " \
                         "of GraphLab Create.")

    # if source is newer than target, fail
    if source_ps._schema_version > target_ps._schema_version:
        raise ValueError("Cannot copy from a version %d Predictive Service " \
                         "to a version %d Predictive Service." % \
                         (source_ps._schema_version, target_ps._schema_version))

    if target_ps._schema_version != PREDICTIVE_SERVICE_SCHEMA_VERSION:
        raise RuntimeError('Target Predictive Service has schema version %s, '
            'copy_predictive_object is only supported if target Predictive Service '
            'is of schema version %s' % (target_ps._schema_version, PREDICTIVE_SERVICE_SCHEMA_VERSION))

    # make sure no extra local changes
    target_ps._ensure_no_local_changes()

    if source_po_name not in source_ps.deployed_predictive_objects:
        raise ValueError("No predictive object named \"%s\" in the source " \
                         "Predictive Service (%s)" % (str(source_po_name), str(source_ps.name)))

    # set the target predictive object name
    target_po_name = source_po_name if not target_po_name else target_po_name

    # get the version for the target predictive service
    if target_po_name in target_ps.deployed_predictive_objects:
        if update is False:
            raise RuntimeError("Cannot update the predictive object %s in the target Predictive Service." \
                            "Please set update to True if you want to update this predictive object in the" \
                            "target Predictive Service." % target_po_name)

        target_version = 1 + target_ps.deployed_predictive_objects[target_po_name]['version']
    else:
        target_version = 1

    # get predictive object info
    source_po_info = source_ps._endpoints[source_po_name]

    po_info = {'version': target_version,
               'docstring': source_po_info['docstring'],
               'cache_state': source_po_info['cache_state'],
               'schema_version': source_po_info['schema_version'],
               'type': source_po_info.get('type', 'model'),
               'description': source_po_info['description']}

    # get path for predictive objects
    if source_po_info.get('type', 'model') == 'model':
        # check if source po is directory or file
        is_dir = True
        if source_po_info['schema_version'] < 3:
            is_dir = False

        source_path = source_ps._get_predictive_object_save_path(source_po_name, source_po_info['version'])
        target_path = target_ps._get_predictive_object_save_path(target_po_name, target_version)

        # compare credentials
        _check_aws_credentials(source_ps._environment.aws_credentials,
                               target_ps._environment.aws_credentials, source_path)

        # intra s3 copy model
        _file_util.intra_s3_copy_model(source_path, target_path, is_dir, target_ps._environment.aws_credentials)

    # add po_info to target_ps
    target_ps._endpoints[target_po_name] = po_info

    # save state to s3
    target_ps._save_state()
    try:
        target_ps._environment.poke()
    except _ConnectionError as e:
        _logger.warn("Unable to connect to target Predictive Service: %s" %
                     (e.message))
    target_ps._update_local_state()
    _logger.info("Successfully copied predictive object \"%s\" from Predictive Service (%s) " \
                 "to Predictive Service (%s)." % (str(source_po_name),
                 str(source_ps.name), str(target_ps.name)))

def _check_aws_credentials(src_credentials, tgt_credentials, source_path):
    # check if credentials are the same
    if src_credentials['aws_access_key_id'] == tgt_credentials['aws_access_key_id'] and \
            src_credentials['aws_secret_access_key'] == tgt_credentials['aws_secret_access_key']:
        return

    # make sure tgt_credentials can be used to access source path
    try:
        conn = _connect_s3(**tgt_credentials)
        (bucket_name, s3_directory) = _file_util.parse_s3_path(source_path)
        bucket = conn.get_bucket(bucket_name)
        key = bucket.get_key(s3_directory)
        if not key:
            raise RuntimeError("Unable to find the key within the S3 bucket. Please check your \
                            aws credentials.")
    except Exception as e:
        raise RuntimeError("Unable to access the correct S3 bucket. Please check your aws credentials.")
