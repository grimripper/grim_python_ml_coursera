import graphlab as _gl
from graphlab.toolkits._model import _get_default_options_wrapper
from graphlab.toolkits.feature_engineering._feature_engineering import Transformer
from graphlab.toolkits._internal_utils import _toolkit_repr_print
from graphlab.toolkits._internal_utils import _precomputed_field
from graphlab.util import _raise_error_if_not_of_type

import _internal_utils
from _doc_utils import republish_docs

_fit_examples_doc = '''
            # Create the data
            >>> sf = graphlab.SFrame({'a' : [1,2,3], 'b' : [2,3,4]})

            # Bin the features ['a', b']
            >>> binner = graphlab.feature_engineering.FeatureBinner(
                                features = ['a', 'b'], strategy='quantile')
            >>> binner = binner.fit(sf)

            # Describe the bins in detail
            >>> fit_binner['bins']

            Columns:
              column  str
              name  str
              left  float
              right  float

            Rows: 20

            Data:
            +--------+----------------+---------------------+--------------------+
            | column |      name      |         left        |       right        |
            +--------+----------------+---------------------+--------------------+
            |   a    | (-Inf, 1.000]  | -1.79769313486e+308 |        1.0         |
            |   a    | (1.000, 1.000] |         1.0         |        1.0         |
            |   a    | (1.000, 1.000] |         1.0         |        1.0         |
            |   a    | (1.000, 1.000] |         1.0         |        1.0         |
            |   a    | (1.000, 2.000] |         1.0         |        2.0         |
            |   a    | (2.000, 2.000] |         2.0         |        2.0         |
            |   a    | (2.000, 2.000] |         2.0         |        2.0         |
            |   a    | (2.000, 3.000] |         2.0         |        3.0         |
            |   a    | (3.000, 3.000] |         3.0         |        3.0         |
            |   a    |  (3.000, Inf]  |         3.0         | 1.79769313486e+308 |
            +--------+----------------+---------------------+--------------------+
            [20 rows x 4 columns]

'''

_fit_transform_examples_doc = '''
            # Create the data
            >>> sf = graphlab.SFrame({'a' : [1,2,3], 'b' : [2,3,4]})

            # Fit and transform on the data.
            >>> binner = graphlab.feature_engineering.FeatureBinner(
                            features = ['a', 'b'], strategy = 'logarithmic')
            >>> binned_sf = binner.fit_transform(sf)
            Columns:
                    a  str
                    b  str

            Rows: 3

            Data:
            +-----------+---------+
            |     a     |    b    |
            +-----------+---------+
            | (-Inf, 1] | (1, 10] |
            |  (1, 10]  | (1, 10] |
            |  (1, 10]  | (1, 10] |
            +-----------+---------+
            [3 rows x 2 columns]
'''

_transform_examples_doc = '''
            #  Logarithmic binning (default)
            # ------------------------------------------------------------------

            # Create the data.
            >>> sf = graphlab.SFrame({'a' : range(100), 'b' : range(100)})

            # Fit the feature binner.
            >>> binner = graphlab.feature_engineering.FeatureBinner(
                            features = ['a', 'b'], strategy = 'logarithmic')
            >>> fit_binner = binner.fit(sf)

            # Transformed on the some new data).
            >>> new_sf = graphlab.SFrame({'a' : range(10), 'b' : range(10)})
            >>> binned_sf = fit_binner.transform(new_sf)

             Columns:
               a  str
               b  str

             Rows: 10

             Data:
             +-----------------+-----------------+
             |        a        |        b        |
             +-----------------+-----------------+
             |  (-Inf, 1.000]  |  (-Inf, 1.000]  |
             |  (-Inf, 1.000]  |  (-Inf, 1.000]  |
             | (1.000, 10.000] | (1.000, 10.000] |
             | (1.000, 10.000] | (1.000, 10.000] |
             | (1.000, 10.000] | (1.000, 10.000] |
             | (1.000, 10.000] | (1.000, 10.000] |
             | (1.000, 10.000] | (1.000, 10.000] |
             | (1.000, 10.000] | (1.000, 10.000] |
             | (1.000, 10.000] | (1.000, 10.000] |
             | (1.000, 10.000] | (1.000, 10.000] |
             +-----------------+-----------------+
             [10 rows x 2 columns]

            #  Quantile binning
            # ------------------------------------------------------------------

            # Create the data.
            >>> sf = graphlab.SFrame({'a' : range(100), 'b' : range(100)})

            # Fit the feature binner.
            >>> binner = graphlab.feature_engineering.FeatureBinner(
                            features = ['a', 'b'], strategy = 'quantile')
            >>> fit_binner = binner.fit(sf)

            # Transformed on the some new data).
            >>> new_sf = graphlab.SFrame({'a' : range(0, 100, 10), 'b' : range(0, 100, 10)})
            >>> binned_sf = fit_binner.transform(new_sf)

            Columns:
              a  str
              b  str

            Rows: 10

            Data:
            +------------------+------------------+
            |        a         |        b         |
            +------------------+------------------+
            |  (-Inf, 0.000]   |  (-Inf, 0.000]   |
            | (0.000, 10.000]  | (0.000, 10.000]  |
            | (10.000, 20.000] | (10.000, 20.000] |
            | (20.000, 30.000] | (20.000, 30.000] |
            | (30.000, 40.000] | (30.000, 40.000] |
            | (40.000, 50.000] | (40.000, 50.000] |
            | (50.000, 60.000] | (50.000, 60.000] |
            | (60.000, 70.000] | (60.000, 70.000] |
            | (70.000, 80.000] | (70.000, 80.000] |
            |  (80.000, Inf]   |  (80.000, Inf]   |
            +------------------+------------------+
            [10 rows x 2 columns]
'''

@republish_docs
class FeatureBinner(Transformer):
    '''
    Feature binning is a method of turning continuous variables into categorical
    values.

    This is accomplished by grouping the values into a pre-defined number of bins.
    The continuous value then gets replaced by a string describing the bin
    that contains that value.

    FeatureBinner supports both 'logarithmic' and 'quantile' binning strategies.

    Parameters
    ----------
    features : list[str] , optional
        Column names of features to be transformed. If None, all columns are
        selected.

    exclude : list[str] | str | None, optional
        Column names of features to be ignored in transformation. Can be string
        or list of strings. Either 'exclude' or 'features' can be passed, but
        not both.

    strategy : 'logarithmic' | 'quantiles', optional
        If the strategy is 'logarithmic', bin break points are defined by by
        :math:`10^i` for i in [0,...,num_bins]. For instance, if num_bins = 2, the bins
        become (-Inf, 1], (1, Inf]. If num_bins = 3, the bins become (-Inf, 1],
        (1, 10], (10, Inf].

        If the strategy is 'quantile', the bin breaks are defined by the
        'num_bins'-quantiles for that columns data. Quantiles are values that
        separate the data into roughly equal-sized subsets.


    num_bins : int, optional
        The number of bins to group the continuous variables into.

    Returns
    -------
    out : FeatureBinner
        A FeatureBinner object which is initialized with the defined
        parameters.

    See Also
    --------
    graphlab.toolkits.feature_engineering._feature_binner.FeatureBinner
    graphlab.toolkits.feature_engineering.create

    Examples
    --------

    .. sourcecode:: python

        >>> from graphlab.toolkits.feature_engineering import *

        # Construct a feature binner with default options.
        >>> sf = graphlab.SFrame({'a': [1,2,3], 'b' : [2,3,4], 'c': [9,10,11]})
        >>> binner = graphlab.feature_engineering.create(sf,
              FeatureBinner(features = ['a', 'b', 'c'], strategy = 'quantile'))

        # Transform the data using the binner.
        >>> binned_sf = binner.transform(sf)

        # Save the transformer.
        >>> binner.save('save-path')

        # Return the details about the bins
        >>> binner['bins']

        Columns:
          column  str
          name  str
          left  float
          right  float

        Rows: 30

        Data:
        +--------+----------------+---------------------+--------------------+
        | column |      name      |         left        |       right        |
        +--------+----------------+---------------------+--------------------+
        |   a    | (-Inf, 1.000]  | -1.79769313486e+308 |        1.0         |
        |   a    | (1.000, 1.000] |         1.0         |        1.0         |
        |   a    | (1.000, 1.000] |         1.0         |        1.0         |
        |   a    | (1.000, 1.000] |         1.0         |        1.0         |
        |   a    | (1.000, 2.000] |         1.0         |        2.0         |
        |   a    | (2.000, 2.000] |         2.0         |        2.0         |
        |   a    | (2.000, 2.000] |         2.0         |        2.0         |
        |   a    | (2.000, 3.000] |         2.0         |        3.0         |
        |   a    | (3.000, 3.000] |         3.0         |        3.0         |
        |   a    |  (3.000, Inf]  |         3.0         | 1.79769313486e+308 |
        +--------+----------------+---------------------+--------------------+
    '''

    _fit_examples_doc = _fit_examples_doc
    _transform_examples_doc = _transform_examples_doc
    _fit_transform_examples_doc = _fit_transform_examples_doc



    get_default_options = staticmethod(_get_default_options_wrapper(
            '_FeatureBinner', 'toolkits.feature_engineering._feature_binner', 'FeatureBinner', True))

    def __init__(self, features=None, excluded_features=None,
                 strategy='logarithmic', num_bins=10):

        # Process and make a copy of the features, exclude.
        _features, _exclude = _internal_utils.process_features(features, excluded_features)

        # Type checking
        _raise_error_if_not_of_type(num_bins, [int])
        _raise_error_if_not_of_type(strategy, [str])

        # Set up options
        opts = {
          'features': features,
          'strategy': strategy,
          'num_bins': num_bins
        }
        if _exclude:
            opts['exclude'] = True
            opts['features'] = _exclude
        else:
            opts['exclude'] = False
            opts['features'] = _features

        # Initialize object
        proxy = _gl.extensions._FeatureBinner()
        proxy.init_transformer(opts)
        super(FeatureBinner, self).__init__(proxy, self.__class__)

    def _get_summary_struct(self):
        """
        Returns a structured description of the model, including (where relevant)
        the schema of the training data, description of the training data,
        training statistics, and model hyperparameters.

        Returns
        -------
        sections : list (of list of tuples)
            A list of summary sections.
              Each section is a list.
                Each item in a section list is a tuple of the form:
                  ('<label>','<field>')
        section_titles: list
            A list of section titles.
              The order matches that of the 'sections' object.
        """
        _features = _precomputed_field(
            _internal_utils.pretty_print_list(self.get('features')))
        _exclude = _precomputed_field(
            _internal_utils.pretty_print_list(self.get('excluded_features')))


        fields = [
            ("Features", _features),
            ("Excluded_features", _exclude),
            ("Strategy for creating bins", 'strategy'),
            ("Number of bins to use", 'num_bins')
        ]
        section_titles = ['Model fields']

        return ([fields], section_titles)

    def __repr__(self):
        (sections, section_titles) = self._get_summary_struct()
        return _toolkit_repr_print(self, sections, section_titles, width=30)
