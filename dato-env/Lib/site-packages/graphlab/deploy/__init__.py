"""
GraphLab Create offers multiple ways to work with your data beyond your desktop
or laptop.

- Batch processing with job scheduling in a distributed system, using a
  Hadoop Yarn or EC2 cluster running Dato Distributed.
- Real-time querying and consumption of predictive objects (i.e. models) with
  GraphLab Create Predictive Services.

Explore the detailed functionality via the following API documentation or the
`Deployment chapter of the User Guide
<https://dato.com/learn/userguide/deployment/introduction.html>`_, as well as the
`Gallery <https://dato.com/learn/gallery>`_.
"""

__all__ = ['environments', 'jobs', 'job', 'map_job']

# Artifacts
from _job import Job
from _task import Task as _Task
from environment import _Environment
import _dml_job

# Sessions
import _session
_default_session = _session._open()

environments = _session.ScopedSession(_default_session, _Environment, """
View and manage Environments available in the session. Environments currently
available can be listed, loaded, and deleted using this object.

Examples
--------
.. sourcecode:: python

  >>> my_env = graphlab.deploy.environment.Local("init-ex2-env")
  >>> graphlab.deploy.environments
  Environment(s):
  +-------+--------------+------------------+------------------+
  | Index |     Name     |       Type       | Unsaved changes? |
  +-------+--------------+------------------+------------------+
  |   0   | init-ex2-env | LocalEnvironment |       Yes        |
  +-------+--------------+------------------+------------------+

  # Load an environment by index number.
  >>> environment = graphlab.deploy.environments[0]

  # Load an environment by name.
  >>> environment = graphlab.deploy.environments['init-ex2-env']

  # Delete an environment by name (deleting by index number also supported).
  >>> del graphlab.deploy.environments['init-ex2-env']

""")

jobs = _session.ScopedSession(_default_session, Job, """
View and manage all Jobs in the session. Jobs currently available can be
listed, loaded, deleted, and can be visualized in Canvas using this object.

Examples
--------

.. sourcecode:: python

  # Monitor all jobs
  >>> gl.deploy.jobs
  +-------+-------------+--------------------------+---------------------------+
  | Index | Environment |           Name           |       Creation date       |
  +-------+-------------+--------------------------+---------------------------+
  |   0   |    async    | add-Feb-11-2015-00-39-32 | 2015-02-11 00:39:32+00:00 |
  +-------+-------------+--------------------------+---------------------------+

  # Load a Job by index number:
  >>> job = graphlab.deploy.jobs[0]

  # Load a Job by name:
  >>> job = graphlab.deploy.jobs['job-print-hello-world-task-init-ex3-env-1407900916']

  # Visualize a Job in Canvas.
  >>> job.show()

  # Visualize a list of Jobs in Canvas.
  >>> graphlab.deploy.jobs.show()

  # to delete a Job by index number (deleting by name also supported):
  >>> del graphlab.deploy.jobs[0]
""")

import job
import predictive_service

from _predictive_service._model_predictive_object import ModelPredictiveObject as _ModelPredictiveObject
from _predictive_service._predictive_service import PredictiveService

predictive_services =  _session.ScopedSession(_default_session, PredictiveService, """
View and manage all Predictive Services in the session.

Predictive Services currently available can be listed, loaded, deleted, and
visualized in Canvas using this object. This object represents the portion of the
workbench for Predictive Services that have been defined in GraphLab Create.

Examples
--------
.. sourcecode:: python

  >>> graphlab.deploy.predictive_services
  PredictiveService(s):
  +-------+--------------+---------------------------+------------------+
  | Index |     Name     |            Type           | Unsaved changes? |
  +-------+--------------+---------------------------+------------------+
  |   0   |    testPS    |     PredictiveService     |        No        |
  +-------+--------------+---------------------------+------------------+

  # Load a Predictive Service by index.
  >>> ps = graphlab.deploy.predictive_services[0]

  # Load a Predictive Service by name.
  >>> ps = graphlab.deploy.predictive_services['testPS']

  # Load a Predictive Service by s3 path.
  >>> ps = graphlab.deploy.predictive_service.load("s3://bucket/testPS")

  # Visualize a Predictive Service in Canvas.
  >>> ps.show()

  # Visualize a list of Predictive Services in Canvas.
  >>> graphlab.deploy.predictive_services.show()

  # to remove a Predictive Service from local workspace by index number
  # (deleting by name also supported):
  >>> del graphlab.deploy.predictive_services[0]
  # Note: The above operation does NOT terminate the Predictive Service.
""")

def required_packages(packages):
    """
    Decorator to annotate the set of packages required for executing a function.

    Parameters
    ----------
    packages: list[str]
        A list that specifies all required python packages current function uses.
        The dependencies are specified in the format of distutils, like:
            ['mysql==0.3.0', 'abc==1.2.3'].

    Returns
    ----------
    A decorator specialized for required_packages.

    See Also
    --------
    required_files

    Examples
    --------
    An example job definition for generating random names and building an
    :class:`~graphlab.SFrame` from them:

    .. sourcecode:: python

      @graphlab.deploy.required_packages(['names == 0.3.0'])
      def my_function(number = 10):
          import names
          people = [names.get_full_name() for i in range(number)]
          sf = graphlab.SFrame({'names':people})
          return sf

      >>> job = gl.deploy.job.create(my_function, number = 20)

    For predictive objects, use the following:

    .. sourcecode:: python

      @graphlab.deploy.required_packages(['names==0.3.0])
      def my_custom_query(input):
          import names
          return [names.get_first_name() for i in range(input['size'])]

      >>> ps.add('my_custom_query_name', my_custom_query)
      >>> ps.apply_changes()
    """
    def decorator_without_arguments(func):
        # validate python package dependencies, should be a list of strings
        if not isinstance(packages, list) or \
            any([not isinstance(dependency, str) for dependency in packages]):
            raise TypeError(("python package dependencies has to be a list of"
                      "strings like: ['mysql==1.0.0', 'another==0.2.3']"))
        func.func_dict['required_packages'] = packages
        return func
    return decorator_without_arguments

def required_files(files, pattern='*'):
    ''' Packages the dependent file(s) for remote execution.

    Package required files for remote execution. This ensures that code written
    locally can safely run in remote environments. The files will be packaged
    and shipped to the remote execution environment. The files will be laid
    out in the same directory structure, in the remote machine, as was present
    in the current working directory.

    Parameters
    -----------
    files : list[str] | str
        Files can be one of the following types:

        - If 'files' is a string and points to a directory, then all files under
          the directory with the given pattern will be shipped.
        - If 'files' is a string and points to a file, the only the one file is
          shipped, pattern will be ignored.
        - If 'files' is a list of string, then we treat them as a set of files to
          be shipped.

    pattern: str
        The file name pattern, it is used as a filter to filter out files that
        are not needed.

    See Also
    --------
    required_packages

    Examples
    --------

        To include all files in a given directory.

        .. sourcecode:: python

          from graphlab.deploy import required_files
          @required_files('my_module_directory_name', pattern='*.py')
          def my_function(input):
              # my logic
              return output

        To include a list of files required by the function.

        .. sourcecode:: python

          from graphlab.deploy import required_files
          @required_files(['file1.py', 'file2.py'])
          def my_function(input):
              # my logic
              return output

        To include a mix of files and directories of files.

        .. sourcecode:: python

          from graphlab.deploy import required_files
          @required_files(['file1.py', 'folder1'], pattern='*.py')
          def my_function(input):
              # my logic
              return output
    Notes
    ------
    - Note that all files are going to be recorded as a relative path to the
      current working directory. When shipped to remote machine, the files
      are going to be laid out in exactly the same structure as in your folder.
    '''

    import os as _os
    def _find_files(directory, pattern):
        '''get all files in a given directory with given pattern'''
        import fnmatch as _fnmatch
        for root, dirs, files in _os.walk(directory):
            for basename in files:
                if _fnmatch.fnmatch(basename, pattern):
                    filename = _os.path.join(root, basename)
                    yield filename

    def _read_file_content(base_dir, f):
        with open(f, 'r') as src:
            rel_path = _os.path.relpath(f, start=base_dir)
            return {rel_path: src.read()}

    def _read_file_or_directory(base_dir, file_or_dir):
        if _os.path.isfile(file_or_dir):
            return _read_file_content(base_dir, file_or_dir)
        elif _os.path.isdir(file_or_dir):
            ret = {}
            for f in _find_files(file_or_dir, pattern):
                ret.update(_read_file_content(base_dir, f))
            return ret
        else:
            raise TypeError('"%s" is not a file or directory' % file_or_dir)

    if isinstance(files, str) or isinstance(files, unicode):
        files = _os.path.realpath(_os.path.expanduser(files))
        if not _os.path.isdir(files) and not _os.path.isfile(files):
            raise TypeError('"%s" does not point to any file or directory' % files)

        files = [files]

    if not isinstance(files, list) or \
        not all([(isinstance(f, str) or isinstance(f, unicode)) for f in files]):
        raise TypeError('"files" parameter has to be either a file name, directory' \
            ' name or a list of files')

    all_files = {}
    for f in files:
        f = _os.path.realpath(_os.path.expanduser(f))
        all_files.update(_read_file_or_directory(_os.getcwd(), f))

    def decorator_without_arguments(func):
        func.func_dict['required_files'] = all_files
        return func

    return decorator_without_arguments

from _ec2_config import Ec2Config

from ec2_cluster import Ec2Cluster
from hadoop_cluster import HadoopCluster

import ec2_cluster
import hadoop_cluster
