import graphlab as gl
import graphlab.connect as _mt
from graphlab.toolkits._internal_utils import _raise_error_if_not_sframe
import graphlab.toolkits._main as _toolkits_main
from graphlab.toolkits._internal_utils import _map_unity_proxy_to_object


class TreeModelMixin(object):
    """
    Implements common methods among tree models:
    - BoostedTreesClassifier
    - BoostedTreesRegression
    - RandomForestClassifier
    - RandomForestRegression
    """

    def get_feature_importance(self):
        """
        Get the importance of features used by the model.

        The measure of importance of feature X
        is determined by the sum of occurence of X
        as a branching node in all trees.

        Return
        ------
        out : SFrame
            A table with two columns: feature, count,
            ordered by 'count' in desending order.

        Examples
        --------
        >>> m.get_feature_importance()
        Columns:
                feature str
                count   int
        Rows: 14
        Data:
        +-----------------------------+-------+
        |           feature           | count |
        +-----------------------------+-------+
        |          PRI_tau_pt         |   12  |
        | DER_mass_transverse_met_lep |   10  |
        |     DER_deltaeta_jet_jet    |   9   |
        |         DER_mass_MMC        |   6   |
        |         DER_mass_vis        |   5   |
        |           DER_pt_h          |   4   |
        |           PRI_met           |   4   |
        |     PRI_jet_leading_eta     |   3   |
        |    DER_lep_eta_centrality   |   2   |
        |       DER_mass_jet_jet      |   2   |
        +-----------------------------+-------+
        [14 rows x 2 columns]
        """
        metric_name = '.'.join([self.__module__, 'get_feature_importance'])
        _mt._get_metric_tracker().track(metric_name)
        return gl.extensions._xgboost_feature_importance(self.__proxy__)

    def extract_features(self, dataset):
        """
        For each example in the dataset, extract the leaf indices of
        each tree as features.

        For multiclass classification, each leaf index contains #num_class
        numbers.

        The returned feature vectors can be used as input to train another
        supervised learning model such as a
        :py:class:`~graphlab.logistic_classifier.LogisticClassifier`,
        an :py:class:`~graphlab.svm_classifier.SVMClassifier`, or a
        :py:class:`~graphlab.neuralnet_classifier.NeuralNetClassifier`.

        Parameters
        ----------
        dataset : SFrame
            Dataset of new observations. Must include columns with the same
            names as the features used for model training, but does not require
            a target column. Additional columns are ignored.

        Returns
        -------
        out : SArray
            An SArray of dtype array.array containing extracted features.

        Examples
        --------
        >>> data =  graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/regression/houses.csv')

        >>> # Regression Tree Models
        >>> model = graphlab.boosted_trees_regression.create(data,
        ...                           target='price',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['boosted_tree_features'] = model.extract_features(data)
        >>> model = graphlab.random_forest_regression.create(data,
        ...                           target='price',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['random_forest_features'] = model.extract_features(data)

        >>> # Classification Tree Models
        >>> data['is_expensive'] = data['price'] > 30000
        >>> model = graphlab.boosted_trees_classifier.create(data,
        ...                           target='is_expensive',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['boosted_tree_features'] = model.extract_features(data)

        >>> model = graphlab.random_forest_classifier.create(data,
        ...                           target='is_expensive',
        ...                           features=['bath', 'bedroom', 'size'])
        >>> data['random_forest_features'] = model.extract_features(data)
        """
        metric_name = '.'.join([self.__module__, 'extract_features'])
        _mt._get_metric_tracker().track(metric_name)
        _raise_error_if_not_sframe(dataset, "dataset")
        options = dict()
        options.update({'model': self.__proxy__,
                        'model_name': self.__name__,
                        'dataset': dataset})
        target = _toolkits_main.run('supervised_learning_feature_extraction', options)
        return _map_unity_proxy_to_object(target['extracted'])

    def _dump_to_text(self, with_stats):
        """
        Dump the models into a list of strings. Each
        string is a text representation of a tree.

        Parameters
        ----------
        with_stats : bool
            If true, include node statistics in the output.

        Return
        ------
        out : SFrame
            A table with two columns: feature, count,
            ordered by 'count' in desending order.
        """
        return gl.extensions._xgboost_dump_model(self.__proxy__, with_stats)
